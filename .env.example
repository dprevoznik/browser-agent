# LLM Provider Configuration (required)
# Configure each provider you plan to use with JSON configuration
# Replace {account_id} and your-gateway-token with actual values
# These are passed directly to BrowserUse's ChatX classes as kwargs
ANTHROPIC_CONFIG='{"base_url": "optional", "default_headers": {...}}'
OPENAI_CONFIG='{"base_url": "optional", "default_headers": {...}}'
GEMINI_CONFIG='{"http_options": {"base_url": "optional", "headers": {...}}}'
AZURE_OPENAI_CONFIG='{"azure_endpoint": "https://your-resource.openai.azure.com/", "api_version": "2024-02-01"}'
GROQ_CONFIG='{"base_url": "https://api.groq.com/openai/v1"}'
OLLAMA_CONFIG='{"base_url": "http://localhost:11434/v1"}'

# Kernel Platform (required)
# Get your API key from the Kernel platform dashboard
KERNEL_API_KEY="sk_xxxxx"

# S3-compatible for storing downloaded files (required)
S3_BUCKET="browser-agent"
S3_ACCESS_KEY_ID="your-access-key"
S3_ENDPOINT_URL="https://{account_id}.r2.cloudflarestorage.com"
S3_SECRET_ACCESS_KEY="your-secret-key"

# Optional Configuration
# Set to "debug" for verbose browser-use logging
BROWSER_USE_LOGGING_LEVEL="info"

# Set to "false" to disable anonymous telemetry
ANONYMIZED_TELEMETRY="false"
